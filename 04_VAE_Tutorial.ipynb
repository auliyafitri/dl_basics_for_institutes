{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Hands-On Session ‚Äì Introduction to Variational Autoencoder (VAE) with PyTorch\n",
    "\n",
    "\n",
    "Variational Autoencoders are a class of generative models that learn a probabilistic mapping between an input space and a latent space. In contrast to standard autoencoders, VAEs impose a probabilistic structure on the latent space by learning parameters of a distribution (typically Gaussian) for each input.\n",
    "\n",
    "In this session, we will build a VAE that learns to reconstruct MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import matplotlib\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import ipywidgets as widgets\n",
    "import torch.nn.init as init\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import Image, display\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "sns.set()\n",
    "sns.reset_orig()\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_gpu = True\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", \"GPU\" if str(device)=='cuda' else device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 #100\n",
    "capacity = 64\n",
    "latent_dims = 2\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "variational_beta = 1\n",
    "DATASET_PATH = \"./data\" # Path to the folder where datasets are/should be downloaded (e.g. MNIST)\n",
    "CHECKPOINT_PATH = \"./saved_models/VAE\" # Path to the folder where the model weights are to be saved\n",
    "\n",
    "slurm_cpus = min(int(os.cpu_count()), 8)\n",
    "NUM_WORKERS = max(1, slurm_cpus-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Loading the MNIST Dataset\n",
    "\n",
    "We will use the MNIST dataset for training our VAE. Each image is flattened to a 784-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load MNIST training dataset\n",
    "train_dataset = datasets.MNIST(DATASET_PATH, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(DATASET_PATH, train=False, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=max(2, NUM_WORKERS//2),\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n",
    "print(\"#Train dataset:\", len(train_dataset))\n",
    "print(\"#Test dataset:\", len(test_dataset))\n",
    "\n",
    "# Visualize some training data samples\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "grid_img = utils.make_grid(images, nrow=8)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.title('Training Data Samples')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_imgs(img1, img2, title_prefix=\"\"):\n",
    "    # Calculate MSE loss between both images\n",
    "    loss = F.mse_loss(img1, img2, reduction=\"sum\")\n",
    "    # Plot images for visual comparison\n",
    "    grid = torchvision.utils.make_grid(torch.stack([img1, img2], dim=0), nrow=2, normalize=True, value_range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.title(f\"{title_prefix}  MSE Loss: {loss.item():4.2f}\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(2):\n",
    "    # Load example image\n",
    "    img, _ = train_dataset[i]\n",
    "    img_mean = img.mean(dim=[1,2], keepdims=True)\n",
    "\n",
    "    # Shift image by one pixel\n",
    "    SHIFT = 1\n",
    "    img_shifted = torch.roll(img, shifts=SHIFT, dims=1)\n",
    "    img_shifted = torch.roll(img_shifted, shifts=SHIFT, dims=2)\n",
    "    img_shifted[:,:1,:] = img_mean\n",
    "    img_shifted[:,:,:1] = img_mean\n",
    "    compare_imgs(img, img_shifted, \"Shifted -\")\n",
    "\n",
    "    # Set half of the image to zero\n",
    "    img_masked = img.clone()\n",
    "    img_masked[:,:img_masked.shape[1]//2,:] = img_mean\n",
    "    compare_imgs(img, img_masked, \"Masked -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Model Architecture\n",
    "\n",
    "The model consists of:\n",
    "\n",
    "- Encoder: A fully-connected network that outputs the parameters ùúá and log ùúé^2 of the latent distribution.\n",
    "- Reparameterization: A helper function to sample ùëß from the learned distribution.\n",
    "- Decoder: A fully-connected network that reconstructs the input from the latent code.\n",
    "We'll use a simple architecture appropriate for MNIST (images of size 28√ó28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"res/vae.png\", width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
    "        self.fc_mu = nn.Linear(in_features=c*2*7*7, out_features=latent_dims)\n",
    "        self.fc_logvar = nn.Linear(in_features=c*2*7*7, out_features=latent_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x_mu = self.fc_mu(x)\n",
    "        x_logvar = self.fc_logvar(x)\n",
    "        return x_mu, x_logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(x.size(0), capacity*2, 7, 7)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def encode(self, x):\n",
    "        latent_mu, latent_logvar = self.encoder(x)\n",
    "        return latent_mu, latent_logvar\n",
    "        \n",
    "    def decode(self, latent):\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent_mu, latent_logvar = self.encode(x)\n",
    "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
    "        x_recon = self.decode(latent)\n",
    "        return x_recon, latent_mu, latent_logvar\n",
    "    \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.empty_like(std).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization in Deep Learning\n",
    "\n",
    "Proper **weight initialization** is crucial for stable and efficient training of deep neural networks.  \n",
    "If weights are too large, activations can explode; if too small, they can vanish‚Äîboth leading to poor gradient flow and stalled learning.  \n",
    "Good initialization (e.g., **Xavier** or **He initialization**) ensures that signals and gradients propagate at a healthy scale across layers,  \n",
    "helping the model converge faster and achieve better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "        init.ones_(m.weight)\n",
    "        init.zeros_(m.bias)\n",
    "\n",
    "def init_weights_vae(model):\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # Make final decoder conv (named conv1) smaller so sigmoid doesn't saturate \n",
    "    if hasattr(model.decoder, 'conv1'):\n",
    "        w = model.decoder.conv1.weight.data\n",
    "        w.mul_(0.01)  # scale down\n",
    "        if model.decoder.conv1.bias is not None:\n",
    "            model.decoder.conv1.bias.data.zero_()\n",
    "\n",
    "    if hasattr(model.encoder, 'fc_logvar'):\n",
    "        model.encoder.fc_logvar.bias.data.fill_(-4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Loss (with Œ≤-VAE option)\n",
    "\n",
    "A VAE optimizes **two coupled objectives**:\n",
    "\n",
    "1. **Reconstruction loss** ‚Äî how well the decoder rebuilds the input `x` from a latent sample `z`.  \n",
    "   - **MSE** assumes Gaussian observation noise; it often produces **blurrier** images because it penalizes\n",
    "     high-frequency differences, even if they‚Äôre perceptually minor.\n",
    "\n",
    "2. **KL divergence** ‚Äî regularizes the encoder‚Äôs posterior $q_{\\phi}(z \\mid x)$ to match the prior $p(z)=\\mathcal{N}(0,I)$,\n",
    "   encouraging a well-behaved latent space and enabling sampling:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}\\!\\left(q_{\\phi}(z \\mid x)\\,\\|\\,p(z)\\right)\n",
    "= -\\tfrac{1}{2}\\sum_{d}\\Big(1+\\log\\sigma_{d}^{2}-\\mu_{d}^{2}-\\sigma_{d}^{2}\\Big).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"res/recon loss.png\", width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"res/kl div loss.png\", width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_logits = nn.BCEWithLogitsLoss(reduction='sum')  # sum over pixels\n",
    "def loss_function(recon_x, x, mu, logvar, variational_beta):\n",
    "    batch_size = x.size(0)\n",
    "    recon_loss = bce_logits(recon_x.flatten(start_dim=1), x.flatten(start_dim=1))\n",
    "    kldivergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (recon_loss + variational_beta * kldivergence)/batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop with Loss Tracking\n",
    "\n",
    "We now train the model while tracking both the training and validation losses for each epoch. These values will later be visualized to show how the training progresses. We use the Adam optimizer and train the model for several epochs. In each iteration, the loss is computed, backpropagated, and the model parameters are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"res/vae-train.gif\", width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder().to(device)\n",
    "init_weights_vae(vae)\n",
    "print(\"Model architecture\")\n",
    "print(summary(vae, input_size=(batch_size, 1, 28, 28), col_names = ['input_size', 'output_size', 'num_params', 'kernel_size', 'trainable'], device=str(device)) )\n",
    "vae.to(memory_format=torch.channels_last)\n",
    "\n",
    "# ------------- Optimizer -------------\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# ------------- Training loop -------------\n",
    "def train_one_epoch(model, loader, optimizer, loss_beta):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for i, (data, _) in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Forward pass \n",
    "        recon, mu, logvar = model(data)\n",
    "        loss = loss_function(recon, data, mu, logvar, loss_beta)\n",
    "\n",
    "        # Backward + optimize\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        total_loss += loss.detach().cpu().item() \n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / max(1, n_batches)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, loss_beta):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.to(device)\n",
    "            recon, mu, logvar = model(data)\n",
    "            loss = loss_function(recon, data, mu, logvar, loss_beta)\n",
    "            total_loss += loss.detach().cpu().item()\n",
    "            n_batches += 1\n",
    "\n",
    "    return total_loss / max(1, n_batches)\n",
    "\n",
    "\n",
    "# ------------- Run training -------------\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val = float('inf')\n",
    "train_begin_time = time.time()\n",
    "print(f\"Model Training....\")\n",
    "for epoch in range(1, epochs+1):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    train_loss = train_one_epoch(vae, train_loader, optimizer, variational_beta)\n",
    "    val_loss = evaluate(vae, test_loader, variational_beta)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs} ‚Äî train_loss: {train_loss:.3f}, val_loss: {val_loss:.3f}, epoch_time: {time.time()-t0:.1f}s\") #This slows down\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # checkpoint best\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save(vae.state_dict(), './pretrained/vae.pth')\n",
    "        \n",
    "print(f\"Training completed in: {time.time()-train_begin_time:.1f}s\")\n",
    "\n",
    "# load best checkpoint\n",
    "vae.load_state_dict(torch.load('./pretrained/vae.pth'))\n",
    "print(f\"Best val_loss: {evaluate(vae, test_loader, variational_beta)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate various plots for understanding of the model architecture, latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostTrainingVisualizations:\n",
    "    def __init__(self, model, test_loader, train_losses, val_losses, epochs, latent_dim=latent_dims):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.train_losses = train_losses\n",
    "        self.val_losses = val_losses\n",
    "        self.epochs = epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = next(model.parameters()).device \n",
    "\n",
    "    def loss_plot(self):\n",
    "        \"\"\"Visualisation of loss over epochs during training\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, self.epochs + 1), self.train_losses, label='Training Loss')\n",
    "        plt.plot(range(1, self.epochs + 1), self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss Curves')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_samples(self, num_samples=64):\n",
    "        \"\"\"Randomly sample points from latent space and decode to generate images\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "            samples = self.model.decode(z).cpu()\n",
    "            samples = torch.sigmoid(samples)\n",
    "            \n",
    "            grid_img = utils.make_grid(samples, nrow=8)\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(grid_img.permute(1, 2, 0), cmap=\"gray\")\n",
    "            plt.title('Generated Samples')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def reconstruct_images(self, num_images=8):\n",
    "        \"\"\"Reconstruct the images\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            data, _ = next(iter(self.test_loader))\n",
    "            data = data.to(self.device)\n",
    "            recon, _, _ = self.model(data)\n",
    "            recon = torch.sigmoid(recon)\n",
    "\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            for i in range(num_images):\n",
    "                plt.subplot(2, num_images, i + 1)\n",
    "                plt.imshow(data[i].cpu().view(28, 28), cmap='gray')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(2, num_images, i + 1 + num_images)\n",
    "                plt.imshow(recon[i].cpu().view(28, 28), cmap='gray')\n",
    "                plt.axis('off')\n",
    "            plt.suptitle('Top: Original Images | Bottom: Reconstructed Images')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def visualize_latent_space(\n",
    "        self,\n",
    "        reduce: str = \"auto\",          # \"auto\" | \"none\" | \"tsne\"\n",
    "        max_points: int = 20000,       # subsample for speed/clarity\n",
    "        bins: int = 50,\n",
    "        show_hist: bool = True,\n",
    "        show_corr: bool = True,\n",
    "        max_hist_dims: int = 10,\n",
    "        pairplot: bool = True,\n",
    "        pairplot_dims: int = 4,\n",
    "        pairplot_subsample: int = 4000,\n",
    "        standardize: bool = True,     # z-score each dim before hist/corr/pairplot\n",
    "        cmap: str = \"tab10\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        latent visualization:\n",
    "        - 2D scatter (raw 2D latents or TSNE if D>2 and reduce=\"auto\"/\"tsne\")\n",
    "        - Per-dimension histograms\n",
    "        - Correlation heatmap\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        Zs, Ys = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.test_loader:\n",
    "                x = x.to(self.device)\n",
    "                _, mu, _ = self.model(x)             # (recon, mu, logvar)\n",
    "                Zs.append(mu.detach().cpu().numpy())\n",
    "                Ys.append(y.detach().cpu().numpy())\n",
    "        Z = np.concatenate(Zs, axis=0)               # (N,D)\n",
    "        y = np.concatenate(Ys, axis=0)               # (N,)\n",
    "        N, D = Z.shape\n",
    "\n",
    "        # Optional standardization (for hist/corr/pairplot comparability)\n",
    "        Z_std = (Z - Z.mean(0, keepdims=True)) / (Z.std(0, keepdims=True) + 1e-8) if standardize else Z\n",
    "\n",
    "        # Subsample for the main scatter if needed\n",
    "        if max_points is not None and N > max_points:\n",
    "            rng = np.random.RandomState(42)\n",
    "            idx = rng.choice(N, max_points, replace=False)\n",
    "            Z_plot = Z[idx]\n",
    "            y_plot = y[idx]\n",
    "        else:\n",
    "            Z_plot, y_plot = Z, y\n",
    "\n",
    "        # ---------- 1) Main 2D scatter ----------\n",
    "        if D == 2 and reduce in (\"auto\", \"none\"):\n",
    "            Z2 = Z_plot\n",
    "            xlabel, ylabel, title = \"z0\", \"z1\", \"2D Latent Space (Œº)\"\n",
    "        else:\n",
    "            if reduce in (\"auto\", \"tsne\"):\n",
    "                Z2 = TSNE(n_components=2, random_state=42, init=\"pca\", learning_rate=\"auto\").fit_transform(Z_plot)\n",
    "                xlabel, ylabel, title = \"t-SNE dim 1\", \"t-SNE dim 2\", \"t-SNE of Latent Means\"\n",
    "            else:\n",
    "                # If user forced \"none\" with D>2, fallback to first two dims\n",
    "                Z2 = Z_plot[:, :2]\n",
    "                xlabel, ylabel, title = \"z0\", \"z1\", \"Latent (first 2 dims)\"\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sc = plt.scatter(Z2[:, 0], Z2[:, 1], c=y_plot, s=10, alpha=0.7, cmap=cmap)\n",
    "        cbar = plt.colorbar(sc)\n",
    "        cbar.set_label(\"label\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # ---------- 2) Histograms per dimension ----------\n",
    "        if show_hist:\n",
    "            k = int(min(max_hist_dims, D))\n",
    "            cols = min(6, k)\n",
    "            rows = int(np.ceil(k / cols))\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(cols * 3.0, rows * 2.4))\n",
    "            axes = np.array(axes).reshape(rows, cols)\n",
    "            Zk = Z_std[:, :k] if standardize else Z[:, :k]\n",
    "            for i in range(rows * cols):\n",
    "                ax = axes.flat[i]\n",
    "                if i < k:\n",
    "                    ax.hist(Zk[:, i], bins=bins, alpha=0.9)\n",
    "                    ax.set_title(f\"z[{i}]\" + (\" (std)\" if standardize else \"\"))\n",
    "                else:\n",
    "                    ax.axis(\"off\")\n",
    "            fig.suptitle(\"Latent Dimension Histograms\", y=0.995)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # ---------- 3) Correlation heatmap ----------\n",
    "        if show_corr:\n",
    "            k = int(min(max_hist_dims, D))\n",
    "            Zk = Z_std[:, :k] if standardize else Z[:, :k]\n",
    "            corr = np.corrcoef(Zk, rowvar=False)  # (k,k)\n",
    "            plt.figure(figsize=(k * 0.6 + 2, k * 0.6 + 2))\n",
    "            im = plt.imshow(corr, vmin=-1, vmax=1, interpolation=\"nearest\")\n",
    "            plt.title(\"Latent Correlation (Pearson)\")\n",
    "            plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "            plt.xticks(range(k), [f\"z{i}\" for i in range(k)], rotation=90)\n",
    "            plt.yticks(range(k), [f\"z{i}\" for i in range(k)])\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def interpolate_images(self, index1, index2, num_steps=10):\n",
    "        \"\"\"Interpolate two randomly chosen points from prior along predefined number of points between them.\"\"\"\n",
    "        data, _ = next(iter(self.test_loader))\n",
    "        if index1 >= len(data) or index2 >= len(data):\n",
    "            print(\"Index out of range.\")\n",
    "            return\n",
    "        \n",
    "        data = data.to(self.device)\n",
    "        img1, img2 = data[index1], data[index2]\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, mu1, _ = self.model(img1.unsqueeze(0))\n",
    "            _, mu2, _ = self.model(img2.unsqueeze(0))\n",
    "\n",
    "        interpolation = torch.stack([mu1 * (1 - t) + mu2 * t for t in torch.linspace(0, 1, steps=num_steps)])\n",
    "        with torch.no_grad():\n",
    "            recon_images = self.model.decode(interpolation).cpu().view(-1, 1, 28, 28)\n",
    "            recon_images = torch.sigmoid(recon_images)\n",
    "\n",
    "        grid_img = utils.make_grid(recon_images, nrow=num_steps)\n",
    "        plt.figure(figsize=(num_steps, 4))\n",
    "        plt.imshow(grid_img.permute(1, 2, 0), cmap=\"gray\")\n",
    "        plt.title('Latent Space Interpolation')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def latent_variable_arithmetic(self, index1, index2, index3):\n",
    "        \"\"\"Apply latent arithmetic.\"\"\"\n",
    "        data, _ = next(iter(self.test_loader))\n",
    "        if index1 >= len(data) or index2 >= len(data) or index3 >= len(data):\n",
    "            print(\"Index out of range.\")\n",
    "            return\n",
    "\n",
    "        data = data.to(self.device)\n",
    "        img1, img2, img3 = data[index1], data[index2], data[index3]\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, mu1, logvar1 = self.model(img1.unsqueeze(0))\n",
    "            _, mu2, logvar2 = self.model(img2.unsqueeze(0))\n",
    "            _, mu3, logvar3 = self.model(img3.unsqueeze(0))\n",
    "\n",
    "        latent1 = self.model.latent_sample(mu1, logvar1)\n",
    "        latent2 = self.model.latent_sample(mu2, logvar2)\n",
    "        latent3 = self.model.latent_sample(mu3, logvar3)\n",
    "\n",
    "        result_latent = latent1 - latent2 + latent3\n",
    "        with torch.no_grad():\n",
    "            recon_image = self.model.decode(result_latent).cpu().view(28, 28)\n",
    "            recon_image = torch.sigmoid(recon_image)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(6, 6))\n",
    "        for idx, img, title in zip(range(4), [img1, img2, img3, recon_image], \n",
    "                                   [\"Original 1\", \"Original 2\", \"Original 3\", \"Reconstructed\"]):\n",
    "            axes[idx].imshow(img.cpu().view(28, 28), cmap='gray')\n",
    "            axes[idx].set_title(title)\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_latent_manifold(self,\n",
    "        device,\n",
    "        n=20,\n",
    "        xlim=None, ylim=None,          # None => auto from posterior Œº\n",
    "        padding=2,\n",
    "        apply_sigmoid=True,\n",
    "        overlay_loader=None,           # pass your test_loader to overlay Œº\n",
    "        overlay_max=5000,              # subsample overlay points\n",
    "        cmap='gray'\n",
    "    ):\n",
    "        \"\"\"Generation of samples from prior within a predefined grid.\"\"\"\n",
    "        vae = self.model\n",
    "        vae.eval()\n",
    "\n",
    "        # If xlim/ylim not given, estimate from aggregated posterior Œº\n",
    "        if xlim is None or ylim is None:\n",
    "            zs = []\n",
    "            if overlay_loader is None:\n",
    "                raise ValueError(\"Provide xlim/ylim or overlay_loader for auto-range.\")\n",
    "            with torch.no_grad():\n",
    "                for x, _ in overlay_loader:\n",
    "                    x = x.to(device)\n",
    "                    _, mu, _ = vae(x)            # model returns (recon, mu, logvar)\n",
    "                    zs.append(mu.detach().cpu())\n",
    "            Z = torch.cat(zs).numpy()\n",
    "            # generous central range (1st‚Äì99th percentile)\n",
    "            if xlim is None:\n",
    "                xlim = tuple(np.quantile(Z[:,0], [0.01, 0.99]))\n",
    "            if ylim is None:\n",
    "                ylim = tuple(np.quantile(Z[:,1], [0.01, 0.99]))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            xs = torch.linspace(xlim[0], xlim[1], steps=n)\n",
    "            ys = torch.linspace(ylim[0], ylim[1], steps=n)\n",
    "            gx, gy = torch.meshgrid(xs, ys, indexing='xy')    # shapes (n,n)\n",
    "            z = torch.stack([gx, gy], dim=-1).reshape(-1, 2).to(device)\n",
    "\n",
    "            xhat = vae.decoder(z)\n",
    "            if apply_sigmoid:\n",
    "                xhat = torch.sigmoid(xhat)\n",
    "            xhat = xhat.clamp(0, 1).cpu()\n",
    "\n",
    "            # tile into one big canvas\n",
    "            grid = torchvision.utils.make_grid(xhat, nrow=n, padding=padding)  # (C,H,W)\n",
    "            grid_np = grid.permute(1, 2, 0).numpy()\n",
    "            if grid_np.shape[2] == 1:     # grayscale\n",
    "                grid_np = grid_np[..., 0]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        # origin='lower' so (xlim[0], ylim[0]) is bottom-left\n",
    "        ax.imshow(grid_np, extent=[xlim[0], xlim[1], ylim[0], ylim[1]], origin='lower', cmap=cmap)\n",
    "        ax.set_title(\"Decoder manifold in latent space\")\n",
    "        ax.set_xlabel(\"z0\")\n",
    "        ax.set_ylabel(\"z1\")\n",
    "        ax.set_xticks(np.linspace(xlim[0], xlim[1], 5))\n",
    "        ax.set_yticks(np.linspace(ylim[0], ylim[1], 5))\n",
    "\n",
    "        # Optional: overlay posterior Œº points from the dataset\n",
    "        if overlay_loader is not None:\n",
    "            pts, labs = [], []\n",
    "            with torch.no_grad():\n",
    "                for x, y in overlay_loader:\n",
    "                    x = x.to(device)\n",
    "                    _, mu, _ = vae(x)\n",
    "                    pts.append(mu.detach().cpu())\n",
    "                    labs.append(y)\n",
    "                    if overlay_max and sum(p.shape[0] for p in pts) >= overlay_max:\n",
    "                        break\n",
    "            Z = torch.cat(pts)[:overlay_max].numpy()\n",
    "            c = torch.cat(labs)[:overlay_max].numpy() if len(labs) else None\n",
    "            ax.scatter(Z[:, 0], Z[:, 1], c=c, s=8, alpha=0.4, cmap='tab10', edgecolors='none')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PostTrainingVisualizations(vae, test_loader, train_losses, val_losses, epochs, latent_dim=latent_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loss Curve Visualization\n",
    "\n",
    "This cell plots the training and validation loss curves, giving insight into how the model is learning over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.loss_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Reconstruction Comparison\n",
    "\n",
    "Let‚Äôs compare a few original images with their reconstructions from the VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.reconstruct_images(num_images=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Generating New Samples\n",
    "\n",
    "After training, a VAE can act as a **generator**: we draw a latent vector `z` from the prior and pass it through the **decoder** to obtain a new image.\n",
    "\n",
    "**How sampling works**\n",
    "- **Prior sampling:** draw `z ‚àº ùí©(0, I)` and decode `xÃÇ = decoder(z)`.\n",
    "- **Output domain:** if the decoder outputs the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.generate_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Latent Space Diagnostics (scatter + histograms + correlations + pair plot)\n",
    "\n",
    "This visualization collects encoder means \\( \\mu \\) for the test set and provides four views:\n",
    "\n",
    "1. **Main 2-D scatter**\n",
    "   - If latent dim = 2 ‚Üí plots \\((z_0, z_1)\\).\n",
    "   - If latent dim > 2 ‚Üí uses **t-SNE** (or first two dims if chosen).\n",
    "   - Points are colored by label to show class structure/separability.\n",
    "\n",
    "2. **Per-dimension histograms**\n",
    "   - Shape, center, and spread of each \\( z_d \\) reveal prior‚Äìposterior mismatch\n",
    "     (e.g., means far from 0 or std ‚â† 1 suggest misalignment with \\( \\mathcal{N}(0,I) \\)).\n",
    "\n",
    "3. **Correlation heatmap**\n",
    "   - Pearson correlations across latent dimensions. Strong off-diagonals\n",
    "     indicate redundancy / limited disentanglement.\n",
    "\n",
    "4. **Pairwise scatter matrix**\n",
    "   - Off-diagonal scatter for selected dims; diagonal shows histograms.\n",
    "   - Useful for spotting clusters, nonlinear relations, and outliers.\n",
    "\n",
    "**How to read**\n",
    "- **Tight, separated clusters** ‚Üí informative latents.\n",
    "- **Global shift/scale** ‚Üí prior mismatch (sampling may degrade).\n",
    "- **High correlations** ‚Üí entangled factors; consider TC/Œ≤-VAE variants.\n",
    "- **Sparse/outlier regions** ‚Üí off-manifold areas likely decode poorly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.visualize_latent_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Latent Space Interpolation\n",
    "\n",
    "**Goal:** Demonstrate that the latent space is (approximately) smooth by taking two points in latent\n",
    "space (by randomly sampling from prior), and decoding a sequence of interpolated latent codes to visualize a gradual morph.\n",
    "\n",
    "**Steps**\n",
    "1. Pick two points \\(x_a, x_b\\).\n",
    "3. Interpolate between them:\n",
    "   - **Lerp (linear):** \\( z_t = (1-t)\\,\\mu_a + t\\,\\mu_b \\)\n",
    "4. Decode each \\(z_t\\) to get intermediate images and tile them in order.\n",
    "\n",
    "**Interpretation**\n",
    "- **Smooth transitions** suggest a well-structured latent geometry.\n",
    "- **Artifacts or jumps** often indicate off-manifold regions or prior‚Äìposterior mismatch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact_manual(viz.interpolate_images,\n",
    "                 model=widgets.fixed(vae),\n",
    "                 index1=widgets.IntSlider(value=0, min=0, max=9, step=1, description='Image 1', continuous_update=False),\n",
    "                 index2=widgets.IntSlider(value=1, min=0, max=9, step=1, description='Image 2', continuous_update=False),\n",
    "                 num_steps=widgets.IntSlider(value=10, min=5, max=20, step=1, description='Steps', continuous_update=False),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Latent Variable Arithmetic\n",
    "\n",
    "**Objective.** Show that simple vector arithmetic in the latent space can induce **semantically coherent** changes in decoded images.\n",
    "\n",
    "**Idea.** Sample 3 points from latent space `(A, B, C)` and form\n",
    "$$\n",
    "z_{\\text{result}} = \\mu_A - \\mu_B + \\mu_C,\n",
    "$$\n",
    "then decode \\(z_{result}\\). If the latent space is well-structured, the decoded image reflects ‚ÄúA without what B had, plus what C had‚Äù.\n",
    "\n",
    "**Why this can work (and limits).**\n",
    "- VAEs encouraged toward a smooth, locally linear latent geometry; linear moves can map to consistent semantic edits.\n",
    "- Works best when latents are **well-regularized** (e.g., suitable \\(\\beta\\), KL scheduling) and relatively **disentangled**.\n",
    "- Not guaranteed: arithmetic may fail if factors are entangled or the move leaves the **data manifold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact_manual(\n",
    "    viz.latent_variable_arithmetic,\n",
    "    index1=widgets.IntSlider(0, 0, 9, 1, description='Image 1', continuous_update=False),\n",
    "    index2=widgets.IntSlider(1, 0, 9, 1, description='Image 2', continuous_update=False),\n",
    "    index3=widgets.IntSlider(1, 0, 9, 1, description='Image 3', continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Decoder Manifold (20√ó20 Grid)\n",
    "\n",
    "This plot shows a **20√ó20 grid of images decoded from a 2-D latent space**.\n",
    "\n",
    "Latent codes \\( z = (z_0, z_1) \\) are sampled uniformly over the range \\([-1.5, 1.5]^2\\).  \n",
    "Each point in this grid is passed through the **VAE decoder**, and the resulting images are tiled such that:\n",
    "\n",
    "- The **horizontal axis** corresponds to \\( z_0 \\)\n",
    "- The **vertical axis** corresponds to \\( z_1 \\)\n",
    "\n",
    "**Interpretation:**  \n",
    "Smooth transitions across the grid indicate a well-organized latent space, where nearby points in the latent space produce similar outputs.  \n",
    "Regions with blurry or unrealistic images (often near the edges) suggest areas of latent space that were under-represented during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple: fixed range\n",
    "viz.plot_latent_manifold(device, n=20, xlim=(-1.5, 1.5), ylim=(-1.5, 1.5), overlay_loader=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Built a simple VAE model in PyTorch.\n",
    "- Trained the model on the MNIST dataset.\n",
    "- Visualized both newly generated samples and the reconstruction quality on test images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
